{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy 101\n",
    "\n",
    "### Por: Fernando Gómez Perera\n",
    "\n",
    "SpaCy es una librería que puede parecer compleja, pero en realidad es muy simple e intuitiva de usar. Sin embargo, es muy poderosa. De hecho, es mucho más poderosa de lo que imaginé, y este proyecto me ha permitido comprobarlo.\n",
    "\n",
    "SpaCy facilita mucho las tareas relacionadas al Procesamiento del Lenguaje Natural. Pero primero, ¿Qué es NLP (en inglés, Natural Language Processing)? Para ello, definamos Lenguaje Natural.\n",
    "\n",
    "## El Lenguaje Natural y su procesamiento\n",
    "\n",
    "El **lenguaje natural** es un concepto por mucho muy simple: Es el lenguaje que usamos los seres humanos para comunicarnos. Dentro de este concepto, podemos englobar lo que decimos, lo que escuchamos, lo que escribimos y lo que leemos. Con ello expresamos ideas, sentimientos, nos quejamos, cantamos, nos inspiramos... Todo eso se puede incluir dentro del lenguaje natural.\n",
    "\n",
    "Para nosotros resulta muy sencillo procesar esta información. Nuestro cerebro es capaz de procesar esta información de forma casi intuitiva, pues conforme crecemos aprendemos a desarrollar estos sentidos, mejoramos nuestro conocimiento de los idiomas, y realizamos estas tareas de forma casi automática, como respirar.\n",
    "\n",
    "Sin embargo, para una computadora esto no es posible. No solamente no pueden procesar esta información de forma simple: La tarea de procesar lenguaje natural resulta por mucho muy compleja, por todo lo que rodea al lenguaje: Sentimientos, conocimiento previo, experiencia, recuerdos... Una computadora no posee ninguna de estas herramientas en su haber. Es ahí donde el Procesamiento del Lenguaje Natural entra al rescate.\n",
    "\n",
    "El **Procesamiento del Lenguaje Natural** es una subrama de la **Inteligencia Artificial**, cuyo objetivo es el procesamiento *automático* o *semi-automático* del lenguaje natural humano dentro de una computadora. En ella se mezclan distintas ramas de las Ciencias de la Computación, como la programación y la *Lingüística Computacional*, así como otras áreas como la *Estadística*.\n",
    "\n",
    "Esta área está más presente en nuestra vida de lo que parece. Podemos encontrar aplicaciones en los asistentes inteligentes, como Cortana, o el corrector ortográfico de Microsoft Word.\n",
    "\n",
    "## NLP con SpaCy\n",
    "Finalmente, SpaCy no es más que una de las muchas herramientas que existen en el mercado para facilitar las tareas relacionadas al NLP, usando para ello Python.\n",
    "\n",
    "SpaCy incluye muchas funcionalidades enfocadas a resolver los problemas más comúnes que existen al momento de procesar texto de forma computacional. Basa su funcionamiento en modelos de datos, los cuales ya se encuentran listos para su uso. Estos modelos incluyen en su interior reglas específicas del lenguaje, reglas para separar texto (*tokenización*), y otras herramientas para analizar texto abierto de forma sencilla usando *análisis basado en reglas* o *Machine Learning* para ello. Estos modelos pueden ser datasets (que en NLP se conocen como *corpus*), o clases de Python donde se representan idiomas completos.\n",
    "\n",
    "En este ejemplo, tomaremos el segundo caso, y analizaremos texto usando la clase del idioma Inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero es necesario importar la clase del idioma\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta clase contiene en su interior todo un conjunto de atributos y métodos relacionados al procesamiento del texto en idioma inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos la clase. Por convencion, se usa el nombre nlp para este objeto\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este objeto, podemos procesar cadenas de texto de forma simple. SpaCy crea un objeto de tipo *Doc* a partir del texto, con el cual se representa un documento en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de un texto en inglés. Por convencion se almacena en la variable doc\n",
    "moses = \"Come on now, don't you want to see this thing that's happening to me. Like Moses has power over sea so you've got a power over me.\\n\\\n",
    "Come on now, don't you want to know that you're a refuge, somewhere I can go. And you're air that, air that I can breathe. \\\n",
    "You're my golden opportunity.\\n\\\n",
    "And oh, oh yes I would, Iif I only could. And you know I would and baby I, oh baby I, I wish.\\n\\\n",
    "Come on now, don't you want to see just what a difference you've made to me. \\\n",
    "I'll be waiting no matter what you say and I'll keep waiting for days and days and days.\\n\\\n",
    "I wish \\n\\\n",
    "Oh, oh, oh. Oh, oh, oh. If the sky's gonna fall down let it fall on me, if you're gonna break down you can break on me.\\n\\\n",
    "If the sky's gonna fall down let it fall on me, oh Lord, let it fall on me\"\n",
    "\n",
    "doc = nlp(moses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este objeto separa el texto en *tokens*, que son simples fragmentos del mismo de acuerdo a un nivel del texto (palabra, oración...). Por defecto, el texto se separa a nivel de palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Come\n",
      "on\n",
      "now\n",
      ",\n",
      "do\n",
      "n't\n",
      "you\n",
      "want\n",
      "to\n",
      "see\n"
     ]
    }
   ],
   "source": [
    "# Se puede iterar el objeto doc usando los tokens del texto.\n",
    "for token in doc[0:10]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada token contiene atributos, llamados *atributos léxicos*, los cuales son los atributos que caracterizan a ese token, como su categoría (alfanumérico, dígito, letra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  want\n",
      "Puntuación:  False\n",
      "Dígito:  False\n",
      "Minúsculas:  True\n",
      "Stop word:  False\n",
      "ASCII válidos:  True\n"
     ]
    }
   ],
   "source": [
    "# Caracteristicas del token\n",
    "token = doc[7]\n",
    "# Texto del token\n",
    "print(\"Token: \", token.text)\n",
    "# ¿El token es un signo de puntuacion?\n",
    "print(\"Puntuación: \", token.is_punct)\n",
    "# ¿El token es un digito?\n",
    "print(\"Dígito: \", token.is_digit)\n",
    "# ¿El token es de letras minusculas?\n",
    "print(\"Minúsculas: \", token.is_lower)\n",
    "# ¿EL token es una stop word?\n",
    "print(\"Stop word: \", token.is_stop)\n",
    "# ¿El token contiene solamente caracteres ASCII validos?\n",
    "print(\"ASCII válidos: \", token.is_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, cada token tiene *anotaciones lingüísticas*, las cuales permiten identificar los elementos propios del texto para su análisis morfológico. Dentro de esas anotaciones se encuentran su etiqueta *POS (Part-of-Speech)*, su representación como *lemma (forma base de la palabra, como aparece en el diccionario)* , entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Come', 'Come', 'come', ''),\n",
       " ('on', 'on', 'on', ''),\n",
       " ('now', 'now', 'now', ''),\n",
       " (',', ',', ',', ''),\n",
       " ('do', 'do', 'do', ''),\n",
       " (\"n't\", 'not', \"n't\", 'RB'),\n",
       " ('you', 'you', 'you', ''),\n",
       " ('want', 'want', 'want', ''),\n",
       " ('to', 'to', 'to', ''),\n",
       " ('see', 'see', 'see', ''),\n",
       " ('this', 'this', 'this', ''),\n",
       " ('thing', 'thing', 'thing', ''),\n",
       " ('that', 'that', 'that', ''),\n",
       " (\"'s\", 'have', \"'s\", ''),\n",
       " ('happening', 'happen', 'happening', '')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anotaciones de los tokens\n",
    "[(token.text, token.lemma_, token.lower_, token.tag_) for token in doc[0:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
